{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows') #Reseteamos a ver el numero de filas normal\n",
    "pd.reset_option('display.max_columns') #Reseteamos a ver el numero de columnas normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows') #Reseteamos a ver el numero de filas normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Para ver todas las columnas a la par\n",
    "pd.set_option('display.max_rows', None) # Vemos todas las filas a la par (No hacerlo con tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lector de CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pernoctar = pd.read_csv(\"pernocta.csv\",index_col=0)\n",
    "viajero = pd.read_csv(\"viajeros.csv\",index_col=0)\n",
    "\n",
    "hosteleria = pd.read_csv(\"hosteleria.csv\",index_col=0)\n",
    "\n",
    "tweet_cleaned = pd.read_csv(\"tweet_cleaned.csv\", index_col=0 )\n",
    "tweet_positive = pd.read_csv(\"positivos.csv\", index_col=0)\n",
    "tweet_neutral = pd.read_csv(\"neutros.csv\", index_col=0)\n",
    "tweet_negative = pd.read_csv(\"negativos.csv\", index_col=0)\n",
    "\n",
    "tweets_cl_sum = pd.read_csv(\"tweets_cl-sum.csv\",index_col = 0)\n",
    "tweets_cl_sum_escala = pd.read_csv(\"tweets_cl_sum_escala.csv\",index_col = 0)\n",
    "\n",
    "sum_escala = pd.read_csv(\"tweets_cl_sum_escala.csv\", index_col=0)\n",
    "sum_escala_shifted = pd.read_csv(\"sum_escala_shifted.csv\", index_col=0)\n",
    "hosteleria_escala = pd.read_csv(\"hosteleria_escala.csv\", index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escribir a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned.to_csv(\"tweet_cleaned.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "tweet_negative.to_csv(\"negativos.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_neutral.to_csv(\"neutros.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_positive.to_csv(\"positivos.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "tweet_negative_sum_escala.to_csv(\"tweet_negative_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_neutral_sum_escala.to_csv(\"tweet_neutral_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_positive_sum_escala.to_csv(\"tweet_positive_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "sum_escala_shifted.to_csv(\"sum_escala_shifted.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "tweets_cl_sum.to_csv(\"tweets_cl-sum.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweets_cl_sum_escala.to_csv(\"tweets_cl_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "hosteleria.to_csv(\"hosteleria.csv\", date_format=\"%Y-%m-%d\")\n",
    "hosteleria_escala.to_csv(\"hosteleria_escala.csv\", date_format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viajeros.to_csv(\"viajeros.csv\", date_format=\"%Y-%m-%d\")\n",
    "pernocta.to_csv(\"pernocta.csv\", date_format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\"EDA_atribus/borja.json\"\n",
    "tweets = pd.read_json(url) #Leemos el dataset cedido por atribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tweets[\"lang\"] == \"en\" # Creamos mascara para separar por idiomas los tweets\n",
    "\n",
    "filtrado = tweets.loc[mask]\n",
    "filtrado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = tweets.loc[:,\"lang\"].value_counts() # Investigamos los lenguajes de los tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tweets.loc[:,\"date_created\"].sort_values() # Para ver el rango de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.loc[:,\"twitters_users_id\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned = tweets.drop([\"count_list\",\"twitters_users_id\",\"sentiment_train\",\"twitters_tweets_id\",\"sentiment_human\",\"pln\",\"pln_ner_label\",\"lang\",\"ocr\",\"is_delete\",\"is_favorite\",\"bot_self_declared\",\"bot_fake_follower\",\"bot_financial\",\"bot_spammer\",\"bot_other\",\"bot_astroturf\",\"bot_cap\",\"bot_feature\",\"is_default_profile_image\",\"moderate\",\"alert\",\"is_retweet\",\"is_reply\",\"type\",\"quoted_twitters_tweets_id\",\"retweet_twitters_tweets_id\",\"reply_twitters_users_id\",\"reply_twitters_tweets_id\",\"retweet_twitters_users_id\",\"name\",\"screen_name\",\"category_id\",\"search_id\",\"source\",\"text\",\"picture\",\"date_created\",\"location\",\"latitude\",\"longitude\",\"county\",\"county_code\",\"country\",\"country_code\",\"description\",\"url\",\"avatar\",\"gender\",\"is_verified\",\"age\",\"list_hobbie\",\"list_job\"],axis=1) #Eliminamos las columnas que no nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned.describe() #Obtenemos información estadística básica del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned.set_index([\"datetime_created\"], inplace=True)\n",
    "tweet_cleaned.index = pd.to_datetime(tweet_cleaned.index)  #Convertimos la fecha en el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned.index = pd.to_datetime(tweet_cleaned.index) #Convertimos las fechas a formato datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned = tweet_cleaned[tweet_cleaned.index >= \"2020-07-01\"] #Dado que los datos de antes de esta fecha tienen muchos meses en blanco y son esporadicos los eliminamos (perdemos menos de un 1% de los datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cleaned.to_csv(\"tweet_cleaned.csv\", date_format=\"%Y-%m-%d\") # Guardamos a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_positive = tweet_cleaned.loc[tweet_cleaned[\"sentiment\"] == 1]\n",
    "tweet_neutral = tweet_cleaned.loc[tweet_cleaned[\"sentiment\"] == 0]\n",
    "tweet_negative = tweet_cleaned.loc[tweet_cleaned[\"sentiment\"] == -1]\n",
    "\n",
    "#Creamos tres datasets basandonos en el anterior, usando el sentimiento de los tweets para ello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_negative.index = pd.to_datetime(tweet_negative.index)\n",
    "tweet_neutral.index = pd.to_datetime(tweet_neutral.index)\n",
    "tweet_positive.index = pd.to_datetime(tweet_positive.index) \n",
    "#Convertimos las fechas a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_positive = pd.read_csv(\"positivos.csv\", index_col=0)\n",
    "tweet_neutral = pd.read_csv(\"neutros.csv\", index_col=0)\n",
    "tweet_negative = pd.read_csv(\"negativos.csv\", index_col=0)\n",
    "#Guardamos los nuevos dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_negative.to_csv(\"negativos.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_neutral.to_csv(\"neutros.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_positive.to_csv(\"positivos.csv\", date_format=\"%Y-%m-%d\")\n",
    "#Guardamos a csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_negative_sum = tweet_negative.resample(\"M\").sum()\n",
    "tweet_neutral_sum = tweet_neutral.resample(\"M\").sum()\n",
    "tweet_positive_sum = tweet_positive.resample(\"M\").sum()\n",
    "\n",
    "#Hacemos un resample y un sum para agregar todos los datos por meses\n",
    "\n",
    "tweet_negative_sum = tweet_negative_sum.to_csv(\"tweet_negative_sum.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_neutral_sum = tweet_neutral_sum.to_csv(\"tweet_neutral_sum.csv\", date_format=\"%Y-%m-%d\")\n",
    "tweet_positive_sum = tweet_positive_sum.to_csv(\"tweet_positive_sum.csv\", date_format=\"%Y-%m-%d\")\n",
    "#Guardamos a csv \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "tweet_negative_sum_escala = tweet_negative_sum.copy()\n",
    "tweet_negative_sum_escala.iloc[:,:] = mms.fit_transform(tweet_negative_sum_escala.iloc[:,:])\n",
    "tweet_negative_sum_escala.to_csv(\"tweet_negative_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "tweet_neutral_sum_escala = tweet_neutral_sum.copy()\n",
    "tweet_neutral_sum_escala.iloc[:,:] = mms.fit_transform(tweet_neutral_sum_escala.iloc[:,:])\n",
    "tweet_neutral_sum_escala.to_csv(\"tweet_neutral_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "tweet_positive_sum_escala = tweet_positive_sum.copy()\n",
    "tweet_positive_sum_escala.iloc[:,:] = mms.fit_transform(tweet_positive_sum_escala.iloc[:,:])\n",
    "tweet_positive_sum_escala.to_csv(\"tweet_positive_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "#Escalamos los dataframes ya que si no no podemos comparar bien los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl = tweet_cleaned.copy()\n",
    "\n",
    "tweets_cl_sum = tweets_cl.resample(\"M\").sum()\n",
    "tweets_cl_sum.to_csv(\"tweets_cl-sum.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "tweets_cl_sum_escala = tweets_cl_sum.copy()\n",
    "tweets_cl_sum_escala.iloc[:,:] = mms.fit_transform(tweets_cl_sum_escala.iloc[:,:])\n",
    "tweets_cl_sum_escala.to_csv(\"tweets_cl_sum_escala.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "tweets_cl_count = tweets_cl.resample(\"M\").count()\n",
    "tweets_cl_count\n",
    "tweets_cl_count.to_csv(\"tweets_cl-count.csv\", date_format=\"%Y-%m-%d\")\n",
    "\n",
    "#Hacemos un resample y un sum para agregar todos los datos por meses\n",
    "#Escalamos los dataframes ya que si no no podemos comparar bien los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl_count = tweets_cl.resample(\"M\").count()\n",
    "tweets_cl_count\n",
    "tweets_cl_count.to_csv(\"tweets_cl-count.csv\", date_format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala = pd.read_csv(\"tweets_cl_sum_escala.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum_escala = sum_escala.reset_index(drop=True) # Quitamos el indice ya que nos da problemas\n",
    "sum_escala.loc[-1] = [np.nan] * len(sum_escala.columns) # añadimos fila con valores NaN\n",
    "sum_escala.index = sum_escala.index + 1 # Cambiamos el indice\n",
    "sum_escala.sort_index(inplace=True)\n",
    "columnas = sum_escala.columns\n",
    "nueva_fila = pd.DataFrame({column_name: [np.nan] for column_name in columnas}, index=[pd.to_datetime('2020-06-30')]) # Creamos una nueva fila para que al hacer shift los valores se muevan a esa fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala_shifted = pd.concat([nueva_fila,sum_escala]) # Unimos la nueva fila al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala_shifted = sum_escala_shifted.shift(-1) #hacemos el shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala_shifted.set_index([\"datetime_created\"], inplace=True)\n",
    "sum_escala_shifted.index = pd.to_datetime(sum_escala_shifted.index) \n",
    "#Convertimos datetime a indice y lo convertimos a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala_shifted = pd.read_csv(\"sum_escala_shifted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_escala_shifted.to_csv(\"sum_escala_shifted.csv\", date_format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"origen_turistas.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacion = tweet_cleaned.corr() #Usamos corr para encontrar las correlaciones, si estan muy correlacionados dos columnas podemos quitar una. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(correlacion,\n",
    "            vmin= -1,\n",
    "            annot=True); #Hacemos el heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viajeros = pd.read_clipboard(index_col=\"Fecha\")\n",
    "viajeros.to_csv(\"viajeros.csv\", date_format=\"%Y-%m-%d\") #Cogemos los datos de un excel y los pasamos a un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pernocta = pd.read_clipboard(index_col=\"Fecha\")\n",
    "pernocta.to_csv(\"pernocta.csv\", date_format=\"%Y-%m-%d\") #Cogemos los datos de un excel y los pasamos a un csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pernoctar = pd.read_csv(\"pernocta.csv\",index_col=\"Fecha\")\n",
    "viajero = pd.read_csv(\"viajeros.csv\",index_col=\"Fecha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria = pd.read_csv(\"hosteleria.csv\",index_col=\"Fecha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria = pd.merge(viajero, pernocta, on=\"Fecha\") #Creamos un nuevo dataframe juntando los dos dataframes previos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria[\"Total_Viajeros\"] = hosteleria[\"Españoles_V\"] + hosteleria[\"Extranjeros_V\"]\n",
    "hosteleria[\"Total_Pernoctantes\"] = hosteleria[\"Españoles_P\"] + hosteleria[\"Extranjeros_P\"]\n",
    "hosteleria[\"Total_Españoles\"] = hosteleria[\"Españoles_P\"] + hosteleria[\"Españoles_V\"]\n",
    "hosteleria[\"Total_Extranjeros\"] = hosteleria[\"Extranjeros_V\"] + hosteleria[\"Extranjeros_P\"]\n",
    "hosteleria[\"Total_Turistas\"] = hosteleria[\"Total_Extranjeros\"] + hosteleria[\"Total_Españoles\"]\n",
    "\n",
    "#Creamos nuevas columnas con la suma de viajeros y pernoctantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria = hosteleria.iloc[::-1]# Los datos originalmente estaban ordenados desde el mas reciente al mas antiguo, por lo que les damos la vuelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria = hosteleria.apply(lambda x: x.str.replace(',', '')) #Quitamos las comas de los datos\n",
    "\n",
    "hosteleria = hosteleria.apply(lambda x: x.str.replace('.', '0'))# La ausencia de valores nos causa problemas, por lo que lo cambiamos por 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria = hosteleria.astype(int) # Covertimos los datos de string a entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria.index = pd.to_datetime(hosteleria.index) #Convertimos la fecha a formato datatime como hemos hecho con los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria.index = hosteleria.index + pd.offsets.MonthEnd(1) #Cambiamos la fecha de principio de mes al final, para que coincida con los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria.to_csv(\"hosteleria.csv\", date_format=\"%Y-%m-%d\") #Guardamos los datos en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler()\n",
    "hosteleria_escala = hosteleria.copy()\n",
    "hosteleria_escala.iloc[:,:] = mms.fit_transform(hosteleria_escala.iloc[:,:]) # Escalamos todo con un MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria_escala.to_csv(\"hosteleria_escala.csv\", date_format=\"%Y-%m-%d\") #Guardamos los datos en un csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre = hosteleria.join(tweets_cl_sum_c, how=\"left\") #Hacemos un join para crear un dataframe para hacer correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre = corre.drop([\"Españoles_V\",\"Extranjeros_V\",\"Españoles_P\",\"Extranjeros_P\"], axis =1) #Reducimos las columnas para el heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre = corre.corr() # Hacemos las correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(corre,\n",
    "            vmin= -1,\n",
    "            annot=True); #Hacemos el heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl_sum_c_shift = tweets_cl_sum_c.reset_index(drop=True) # Quitamos el indice ya que nos da problemas\n",
    "tweets_cl_sum_c_shift.loc[-1] = [np.nan] * len(tweets_cl_sum_c_shift.columns) # añadimos fila con valores NaN\n",
    "tweets_cl_sum_c_shift.index = tweets_cl_sum_c_shift.index + 1 # Cambiamos el indice\n",
    "tweets_cl_sum_c_shift.sort_index(inplace=True)\n",
    "\n",
    "tweets_cl_sum_c_shift = tweets_cl_sum_c_shift.reset_index(drop=True)\n",
    "\n",
    "columnas = tweets_cl_sum_c_shift.columns\n",
    "nueva_fila = pd.DataFrame({column_name: [np.nan] for column_name in columnas})\n",
    "nueva_fila = nueva_fila.reset_index(drop=True)\n",
    "\n",
    "tweets_cl_sum_c_shifted = pd.concat([nueva_fila,tweets_cl_sum_c_shift])\n",
    "tweets_cl_sum_c_shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl_sum_c_shifted = tweets_cl_sum_c_shifted.iloc[1:] #Quitamos la primera fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl_sum_c_shifted = tweets_cl_sum_c_shifted.shift(-1) #Hacemos un shift para arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre3 = pd.merge(hosteleria_escala, tweets_cl_sum_escala, left_index=True, right_index=True, how='outer') #Un nuevo dataframe para hacer correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corre3 = corre3.drop([\"Españoles_V\",\"Extranjeros_V\",\"Españoles_P\",\"Extranjeros_P\",\"count_favorite\",\"count_retweet\",\"count_follow\",\"count_follower\",\"Total_Viajeros\",\"Total_Pernoctantes\"],axis=1) #Hacemos drop de datos inncecesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl3 = corre3.corr() #Hacemos la correlacion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correl3,\n",
    "            vmin= -1,\n",
    "            annot=True); #Mostramos la correlacion en un heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = tweets_cl_sum_escala.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(cor,\n",
    "            vmin= -1,\n",
    "            annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cl_sum_escala.index = tweet_negative_sum_escala.index\n",
    "\n",
    "tweets_cl_sum_escala = tweets_cl_sum_escala.set_index(tweet_negative_sum_escala.index)\n",
    "\n",
    "tweet_neutral_sum_escala = tweet_neutral_sum_escala.set_index(tweets_cl_sum_escala.index)\n",
    "\n",
    "tweet_positive_sum_escala = tweet_positive_sum_escala.set_index(tweets_cl_sum_escala.index)\n",
    "\n",
    "hosteleria_escala = hosteleria_escala.set_index(tweets_cl_sum_escala.index)\n",
    "\n",
    "#Hacemos que todos los índices sean iguales 100%, para power bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hosteleria_escala = hosteleria_escala.rename_axis(\"Fecha\") #Cambiamos el nombre del índice a Fecha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
